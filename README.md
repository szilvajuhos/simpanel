# SimPanel
Simulating a tumour gene panel for NGS

The main purpose is to provide a well-defined read set that can be used as a test for panel workflows. It contains no data from real patients, can be modified, etc. 

Software/data used:
 - HG19 FASTA
 - bedtools
 - [wgsim](https://github.com/lh3/wgsim)
 - [bwa](https://github.com/lh3/)
 - [samtools](https://github.com/samtools/)
 - [bamsurgeon](https://github.com/adamewing/bamsurgeon) and all of its dependencies that are not already added but Picard, namely:
   - velvet 
   - exonerate 
   - pysam

## Steps to build the normal dataset:

### Create reference fasta
The bed file `panel_hg19.bed` contains gene regions to be cut from the HG19 FASTA file. These coordinates were actually lifted over from 
GRCh38. This file should not be treated as a concise list of tumour genes whatsoever.

```
 bedtools getfasta -fi hg19.fa -bed panel\_hg19.bed.bed > tumor_panel_37.fasta
```

### Generate normal reads
Reads to be treated as normal can be generated by `wgsim`. The size of the reference is about 200M still, it is really a large panel having 1380 genes:

```
$ grep -v ">" tumor_panel_37.fasta | wc -c
191942266
```
We are making 70M read pairs each read having 151 bps length and including some germline variations (storing these in variations.txt):
```
wgsim -N 70000000 -1 151 -2 151 tumor_panel_37.fasta\
panel_37_N_R1.fastq panel_37_N_R2.fastq 2>&1 | tee variations.txt
```

While reference\_length\*coverage/(2\*readlength) = number\_of\_reads therefore, $coverage = 2\*readlength\*number\_of\_reads/reference\_length$

2x151x70000000/191942266 = 110 coverage can be achieved.

### Align normal reads to make a normal BAM:

Use `bwa` for alignment. You have to have the indexed version of HG19 to do this, if not, start `bwa index hg19.fa` in your lunchbreak. We are using 16 
CPU cores here (`-t 16`) for each process, the alignment takes about two hours:
```
bwa mem -t 16 -M hg19.fa panel_37_N_R1.fastq.gz panel_37_N_R2.fastq.gz\
| samtools sort --threads 16 -m 4G - > normal_panel.bam
samtools index normal_panel.bam
```
Now we have a BAM file with germline normal mutations. With bamsurgeon we can add SNPs and indels. To add a single SNP with 0.5 allele frequency to each 
gene (somewhere at the middle):
```
$ awk '{coord=$2+($3-$2)/2;printf("%s %d %d %2.2f\n",$1,coord,coord,0.5)}'  panel_hg19.bed| head -3
10 52602302 52602302 0.50
1 12715846 12715846 0.50
7 48449073 48449073 0.50
```
Of course the result was redirected to `SNPs.var`. We can run the appropriate bamsurgeon command now:
```
bamsurgeon $ python bin/addsnv.py \
    -v /path/to/SNPs.var\
    -f /path/to/normal_panel.bam\
    -r /path/to/hg19.fa\
    -o /path/to/tumour_panel_SNPs_37.bam
```
Once `tumour_panel_SNPs_37.bam` has been created, it have to be sorted and indexed. The tougher part is now to generate indels. Wrote an 
[awk script](https://github.com/szilvajuhos/simpanel/blob/master/indels.awk) that randomly makes indels around SNPs using the SNPs.var file 
generated earlier: half of indels are close to the SNPs ($+-10 bps$) and the rest are far from them, so we can have a look at the effect of 
indel realignment:

```
awk -f indels.awk SNPs.var |sort -n -k1,1n -n > indels.var
cd /path/to/bamsurgeon
python bin/addindel.py -v /path/to/indels.var -f /path/to/tumour_panel_SNPs_37_sorted.bam -r /path/to/hg19.fa -o /path/to/tumour_panel_SNPs_and_indels_37.bam
```
This file also needs to be sorted/indexed if you want to have a look at in IGV. These two BAM files already can be used for variant call benchmarking, but 
have to extract FASTQs for alignment testing using something like [bam2fastq.sh](https://github.com/NationalGenomicsInfrastructure/ngi_pipeline/blob/master/scripts/bam2fastq.sh)

